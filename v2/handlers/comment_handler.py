import threading
import sys
import os
import time
import concurrent.futures
from typing import List, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ ã—ã¦importã‚’å¯èƒ½ã«ã™ã‚‹
sys.path.insert(
    0,
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)

from v2.core.event_queue import EventQueue
from v2.core.events import CommentResponseReady, PrepareCommentResponse
from v2.services.prompt_manager import PromptManager
from v2.utils.comment_filter import CommentFilter
from v2.handlers.mode_manager import ModeManager, ConversationMode
from v2.handlers.master_prompt_manager import MasterPromptManager
from openai_adapter import OpenAIAdapter
from conversation_history import ConversationHistory
from memory_manager import MemoryManager
from config import config


class CommentHandler:
    """ã‚³ãƒ¡ãƒ³ãƒˆã¸ã®å¿œç­”ç”Ÿæˆã‚’æ‹…å½“ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã€‚"""

    def __init__(
        self,
        event_queue: EventQueue,
        shared_mode_manager: ModeManager = None,
        shared_master_prompt_manager: MasterPromptManager = None
    ):
        self.event_queue = event_queue
        
        # ãƒ¢ãƒ¼ãƒ‰ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆMonologueHandlerã¨å…±æœ‰ï¼‰
        self.mode_manager = shared_mode_manager or ModeManager()
        
        # ãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆMonologueHandlerã¨å…±æœ‰ï¼‰
        self.master_prompt_manager = shared_master_prompt_manager or MasterPromptManager()
        
        # v1ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–
        try:
            print("[CommentHandler] ğŸ” Starting component initialization...")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã®åˆæœŸåŒ–
            print("[CommentHandler] ğŸ” Initializing PromptManager...")
            self.prompt_manager = PromptManager()
            print("[CommentHandler] âœ… PromptManager initialized")
            
            # ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–
            print("[CommentHandler] ğŸ” Initializing CommentFilter...")
            filter_config_path = os.path.join(os.path.dirname(__file__), "../config/comment_filter.json")
            self.comment_filter = CommentFilter(filter_config_path)
            print("[CommentHandler] âœ… CommentFilter initialized")
            
            # OpenAIã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®åˆæœŸåŒ–
            print("[CommentHandler] ğŸ” Initializing OpenAIAdapter...")
            system_prompt_path = os.path.join(config.paths.prompts, "persona_prompt.txt")
            with open(system_prompt_path, "r", encoding="utf-8") as f:
                system_prompt = f.read()
            self.openai_adapter = OpenAIAdapter(system_prompt, silent_mode=False)
            print("[CommentHandler] âœ… OpenAIAdapter initialized")
            
            # ä¼šè©±å±¥æ­´ã¨ãƒ¡ãƒ¢ãƒªç®¡ç†ã®åˆæœŸåŒ–
            print("[CommentHandler] ğŸ” Initializing ConversationHistory...")
            self.conversation_history = ConversationHistory(self.openai_adapter)
            print("[CommentHandler] âœ… ConversationHistory initialized")
            
            print("[CommentHandler] ğŸ” Initializing MemoryManager...")
            self.memory_manager = MemoryManager(self.openai_adapter)
            print("[CommentHandler] âœ… MemoryManager initialized")
            
            print("[CommentHandler] âœ… All components initialized successfully")
        except Exception as e:
            print(f"[CommentHandler] âŒ Failed to initialize components: {e}")
            import traceback
            traceback.print_exc()
            self.prompt_manager = None
            self.comment_filter = None
            self.openai_adapter = None
            self.conversation_history = None
            self.memory_manager = None

    def handle_prepare_comment_response(self, command: PrepareCommentResponse):
        """
        PrepareCommentResponseã‚³ãƒãƒ³ãƒ‰ã‚’å‡¦ç†ã™ã‚‹ã€‚
        ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§LLMã«å•ã„åˆã‚ã›ã€å®Œäº†æ™‚ã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œã™ã‚‹ã€‚
        """
        print(f"[CommentHandler] ğŸ” Received command: {command}")
        print(f"[CommentHandler] ğŸ” Starting background thread for task: {command.task_id}")
        
        try:
            thread = threading.Thread(
                target=self._execute_in_background, 
                args=(command,),
                name=f"CommentProcessor-{command.task_id}",
                daemon=True
            )
            print(f"[CommentHandler] ğŸ” Thread created successfully")
            thread.start()
            print(f"[CommentHandler] ğŸ” Thread started successfully")
        except Exception as e:
            print(f"[CommentHandler] âŒ Failed to start background thread: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
            print(f"[CommentHandler] ğŸ”„ Fallback: executing in main thread")
            self._execute_in_background(command)

    def _execute_in_background(self, command: PrepareCommentResponse):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§LLMå‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ã‚¤ãƒ™ãƒ³ãƒˆã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        try:
            print(f"[CommentHandler] âš¡ Processing {len(command.comments)} comments for task: {command.task_id}")
            print(f"[CommentHandler] ğŸ” Thread info: {threading.current_thread().name}")
            start_time = time.time()
            
            print(f"[CommentHandler] ğŸ” Step 1: Starting comment processing...")
            print(f"[CommentHandler] ğŸ” Checking component availability...")
            print(f"[CommentHandler] ğŸ” - openai_adapter: {'âœ…' if self.openai_adapter else 'âŒ'}")
            print(f"[CommentHandler] ğŸ” - prompt_manager: {'âœ…' if self.prompt_manager else 'âŒ'}")
            print(f"[CommentHandler] ğŸ” - comment_filter: {'âœ…' if self.comment_filter else 'âŒ'}")
            print(f"[CommentHandler] ğŸ” - conversation_history: {'âœ…' if self.conversation_history else 'âŒ'}")
            print(f"[CommentHandler] ğŸ” - memory_manager: {'âœ…' if self.memory_manager else 'âŒ'}")
            
            if not self.openai_adapter:
                print(f"[CommentHandler] âš ï¸ OpenAI adapter not available, using fallback")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚·ãƒ³ãƒ—ãƒ«ãªå¿œç­”
                sentences = ["ã‚³ãƒ¡ãƒ³ãƒˆã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼"]
                event = CommentResponseReady(
                    task_id=command.task_id,
                    sentences=sentences,
                    original_comments=command.comments
                )
                self.event_queue.put(event)
                return
        except Exception as e:
            print(f"[CommentHandler] âŒ Error in initial setup: {e}")
            import traceback
            traceback.print_exc()
            return
        
        try:
            # 1. ä¸¦åˆ—ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            print(f"[CommentHandler] ğŸ” Step 2: Starting parallel comment filtering...")
            filter_start = time.time()
            filtered_comments = self._filter_comments_parallel(command.comments)
            filter_time = time.time() - filter_start
            
            print(f"[CommentHandler] âš¡ Filtering completed: {len(filtered_comments)}/{len(command.comments)} comments in {filter_time:.2f}s")
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã«ã‚³ãƒ¡ãƒ³ãƒˆãŒæ®‹ã£ã¦ã„ãªã„å ´åˆ
            if not filtered_comments:
                print("[CommentHandler] All comments were filtered out, skipping response")
                sentences = []
                event = CommentResponseReady(
                    task_id=command.task_id,
                    sentences=sentences,
                    original_comments=command.comments
                )
                self.event_queue.put(event)
                return
            
            # 2. é«˜é€Ÿãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            print(f"[CommentHandler] ğŸ” Step 3: Building optimized prompt...")
            prompt_start = time.time()
            prompt = self._build_comment_response_prompt_optimized(filtered_comments)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒNoneã®å ´åˆï¼ˆé–¢é€£æ€§ãŒä½ã„ã‚³ãƒ¡ãƒ³ãƒˆï¼‰ã¯å‡¦ç†çµ‚äº†
            if prompt is None:
                print(f"[CommentHandler] ğŸš« Comment not relevant to thought experiment, skipping response")
                return
                
            prompt_time = time.time() - prompt_start
            print(f"[CommentHandler] âš¡ Prompt built in {prompt_time:.2f}s")

            # 3. LLMå¿œç­”ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†è¿½åŠ ï¼‰
            print(f"[CommentHandler] ğŸ” Step 4: Calling LLM for response generation...")
            llm_start = time.time()
            try:
                response_text = self.openai_adapter.create_chat_for_response(prompt)
                llm_time = time.time() - llm_start
                print(f"[CommentHandler] âš¡ LLM response received in {llm_time:.2f}s")
            except Exception as e:
                llm_time = time.time() - llm_start
                print(f"[CommentHandler] âŒ LLM call failed after {llm_time:.2f}s: {e}")
                response_text = None

            if response_text:
                sentences = self._split_into_sentences(response_text)

                # 4. ä¼šè©±å±¥æ­´ã«ä¿å­˜ï¼ˆéåŒæœŸï¼‰
                history_start = time.time()
                self._save_conversation_to_history(filtered_comments, response_text)
                
                # 5. ModeManagerã«AIç™ºè¨€ã‚’è¨˜éŒ²ï¼ˆæ–‡è„ˆä¿æŒã®ãŸã‚ï¼‰
                try:
                    if hasattr(self.mode_manager, 'set_last_ai_utterance'):
                        self.mode_manager.set_last_ai_utterance(response_text)
                    else:
                        print("[CommentHandler] Warning: ModeManager does not have set_last_ai_utterance method")
                except Exception as e:
                    print(f"[CommentHandler] Warning: Failed to record AI utterance: {e}")
                
                history_time = time.time() - history_start

                total_time = time.time() - start_time
                print(f"[CommentHandler] âœ… Comment processing completed: filter={filter_time:.2f}s, prompt={prompt_time:.2f}s, llm={llm_time:.2f}s, history={history_time:.2f}s, total={total_time:.2f}s")

                # 5. çµæœã‚’ã‚¤ãƒ™ãƒ³ãƒˆã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹
                ready_event = CommentResponseReady(
                    task_id=command.task_id,
                    sentences=sentences,
                    original_comments=command.comments
                )
                self.event_queue.put(ready_event)
            else:
                print("[CommentHandler] Warning: Received empty response from LLM")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
                fallback_sentences = ["ã‚³ãƒ¡ãƒ³ãƒˆã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ä»Šã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªã„ã§ã™ã€‚"]
                event = CommentResponseReady(
                    task_id=command.task_id,
                    sentences=fallback_sentences,
                    original_comments=command.comments
                )
                self.event_queue.put(event)

        except Exception as e:
            print(f"[CommentHandler] Error during LLM call: {e}")
            import traceback
            traceback.print_exc()
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
            fallback_sentences = ["ã‚³ãƒ¡ãƒ³ãƒˆã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼"]
            event = CommentResponseReady(
                task_id=command.task_id,
                sentences=fallback_sentences,
                original_comments=command.comments
            )
            self.event_queue.put(event)

    def _split_into_sentences(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡ç« ã«åˆ†å‰²ã™ã‚‹"""
        sentences = text.split("ã€‚")
        sentences = [s.strip() + ("ã€‚" if not s.strip().endswith(("ã€‚", "ï¼", "ï¼Ÿ")) else "") 
                    for s in sentences if s.strip()]
        # æœ€å¾Œã®ç©ºã®æ–‡ç« ã‚’é™¤å»
        if sentences and sentences[-1] == "ã€‚":
            sentences.pop()
        return sentences

    def _build_comment_response_prompt(self, comments: List[Any]) -> str:
        """ã‚³ãƒ¡ãƒ³ãƒˆå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
        # ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆé–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
        comment_texts = [self._extract_comment_text(comment) for comment in comments]
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åä»˜ãã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆèª­ã¿ä¸Šã’ç”¨ï¼‰
        comment_texts_with_username = [self._extract_comment_with_username(comment) for comment in comments]
        
        if not self.prompt_manager:
            return f"ä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆã«è‡ªç„¶ã«è¿”ç­”ã—ã¦ãã ã•ã„ï¼š{', '.join(comment_texts_with_username)}"
            
        if not self.conversation_history or not self.memory_manager:
            # æœ€å°é™ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã®ã¿ä½¿ç”¨
            context = {"comments": comment_texts}
            prompt_template = self.prompt_manager.get_comment_response_prompt(context)
            return prompt_template.format(comments=", ".join(comment_texts_with_username))
            
        try:
            # è©©ã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
            poetry_relevance = self._check_poetry_comment_relevance(comment_texts)
            print(f"[CommentHandler] Poetry comment relevance check: {poetry_relevance}")
            
            # é–¢é€£æ€§ãŒä½ã„å ´åˆã¯ç„¡è¦–ï¼ˆéŸ³å£°å¿œç­”ãªã—ï¼‰
            if not poetry_relevance.get("relevant", False):
                print(f"[CommentHandler] Ignoring comment not related to poetry discussion: {comment_texts}")
                return None  # Noneã‚’è¿”ã™ã“ã¨ã§éŸ³å£°å¿œç­”ã‚’è¡Œã‚ãªã„
            
            # ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯çµ±åˆå¿œç­”ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ
            if self.mode_manager.get_current_mode() != ConversationMode.INTEGRATED_RESPONSE:
                self.mode_manager.switch_mode(
                    target_mode=ConversationMode.INTEGRATED_RESPONSE,
                    has_comments=True,
                    comment_count=len(comments)
                )
            
            self.mode_manager.increment_duration()
            
            print(f"[CommentHandler] Using integrated response mode (comments: {len(comments)})")
            
            # è¨˜æ†¶ã¨å±¥æ­´ã‚’å–å¾—
            memory_summary = self.memory_manager.get_context_summary()
            
            # æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ã¦æ–‡å­—åˆ—åŒ–
            recent_conversations = self.conversation_history.get_recent_conversations("general", limit=5)
            history_str = self._format_conversation_history(recent_conversations)
            
            # æœ€æ–°ã®ç™ºè¨€ã‚’å–å¾—
            if recent_conversations:
                last_conv = recent_conversations[-1]
                last_sentence = last_conv.get("response", last_conv.get("message", "ï¼ˆã¾ã ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰"))
            else:
                last_sentence = "ï¼ˆã¾ã ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰"
            
            # æœ€è¿‘ã®ã‚³ãƒ¡ãƒ³ãƒˆè¦ç´„ã‚’ä½œæˆ
            recent_comments_summary = self._create_recent_comments_summary(comment_texts, recent_conversations)

            # ModeManagerã‹ã‚‰å¤‰æ•°ã‚’å–å¾—ï¼ˆçµ±åˆå¿œç­”ãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰
            variables = self.mode_manager.get_prompt_variables(
                last_sentence=last_sentence,
                history_str=history_str,
                memory_summary=memory_summary,
                recent_comments_summary=recent_comments_summary,
                comment=", ".join(comment_texts_with_username)
            )

            # çµ±åˆå¿œç­”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
            prompt_template = self.prompt_manager.get_prompt_by_filename("integrated_response.txt")
            
            if prompt_template:
                # çµ±åˆå¿œç­”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
                integrated_response_prompt = prompt_template.format(**variables)
                
                # ãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµ±åˆ
                final_prompt = self.master_prompt_manager.wrap_task_with_master_prompt(
                    specific_task_prompt=integrated_response_prompt,
                    memory_summary=memory_summary,
                    conversation_history=history_str,
                    current_mode="integrated_response"
                )
                
                print(f"[CommentHandler] Integrated with master prompt ({len(final_prompt)} chars)")
                return final_prompt
            else:
                print(f"[CommentHandler] integrated_response.txt not found, using fallback")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®æ–¹å¼
                context = {"comments": comment_texts}
                prompt_template = self.prompt_manager.get_comment_response_prompt(context)
                return prompt_template.format(
                    comments=", ".join(comment_texts_with_username),
                    comment=", ".join(comment_texts_with_username),
                    memory_summary=memory_summary,
                    history_str=history_str,
                    last_sentence=last_sentence,
                    recent_comments_summary=recent_comments_summary,
                )
            
        except Exception as e:
            print(f"[CommentHandler] Error building prompt: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šPromptManagerã‚’ä½¿ç”¨
            context = {"comments": comment_texts}
            return self.prompt_manager.get_comment_response_prompt(context)

    def _format_conversation_history(self, conversations: List[dict]) -> str:
        """ä¼šè©±å±¥æ­´ã‚’æ–‡å­—åˆ—ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not conversations:
            return "ï¼ˆä¼šè©±å±¥æ­´ãªã—ï¼‰"
        
        history_parts = []
        for conv in conversations:
            message = conv.get("message", "")
            response = conv.get("response", "")
            timestamp = conv.get("timestamp", "")
            
            if message and response:
                history_parts.append(f"[{timestamp}] ãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}")
                history_parts.append(f"[{timestamp}] AI: {response}")
        
        return "\n".join(history_parts) if history_parts else "ï¼ˆä¼šè©±å±¥æ­´ãªã—ï¼‰"

    def _save_conversation_to_history(self, comments: List[dict], response: str):
        """ä¼šè©±å±¥æ­´ã«è¨˜éŒ²ã‚’ä¿å­˜ã™ã‚‹"""
        if not self.conversation_history:
            print("[CommentHandler] Warning: ConversationHistory not available, skipping save")
            return
        
        try:
            # å„ã‚³ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦è¨˜éŒ²ã‚’ä¿å­˜
            for comment in comments:
                username = comment.get('username', comment.get('user_id', 'unknown_user'))
                message = comment.get('message', '')
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’æ§‹ç¯‰
                user_info = {
                    'user_id': comment.get('user_id', username),
                    'channel_id': comment.get('author', {}).get('channel_id', ''),
                    'is_owner': comment.get('author', {}).get('is_owner', False),
                    'is_moderator': comment.get('author', {}).get('is_moderator', False),
                    'is_verified': comment.get('author', {}).get('is_verified', False),
                    'superchat': comment.get('superchat'),
                    'timestamp': comment.get('timestamp', '')
                }
                
                # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                self.conversation_history.add_conversation(
                    username=username,
                    message=message,
                    response=response,
                    user_info=user_info
                )
                
                print(f"[CommentHandler] Saved conversation to history: {username} -> {message[:30]}...")
                
        except Exception as e:
            print(f"[CommentHandler] Error saving conversation to history: {e}")

    def _create_recent_comments_summary(self, current_comments: List[str], recent_conversations: List[dict]) -> str:
        """æœ€è¿‘ã®ã‚³ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã‚’ä½œæˆ"""
        if not current_comments and not recent_conversations:
            return "ï¼ˆæœ€è¿‘ã®ã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"
        
        summary_parts = []
        
        # ç¾åœ¨ã®ã‚³ãƒ¡ãƒ³ãƒˆ
        if current_comments:
            summary_parts.append(f"ç¾åœ¨ã®ã‚³ãƒ¡ãƒ³ãƒˆ: {', '.join(current_comments)}")
        
        # æœ€è¿‘ã®ä¼šè©±ã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
        if recent_conversations:
            recent_messages = []
            for conv in recent_conversations[-3:]:  # æœ€æ–°3ä»¶
                message = conv.get("message", "")
                if message:
                    recent_messages.append(message)
            
            if recent_messages:
                summary_parts.append(f"æœ€è¿‘ã®ä¼šè©±: {', '.join(recent_messages)}")
        
        return " / ".join(summary_parts) if summary_parts else "ï¼ˆæœ€è¿‘ã®ã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"

    def _extract_comment_text(self, comment: Any) -> str:
        """ã‚³ãƒ¡ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹"""
        # ã‚³ãƒ¡ãƒ³ãƒˆã®å½¢å¼ã«å¿œã˜ã¦é©åˆ‡ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        if hasattr(comment, 'message'):
            return comment.message
        elif hasattr(comment, 'text'):
            return comment.text
        elif hasattr(comment, 'content'):
            return comment.content
        elif isinstance(comment, str):
            return comment
        elif isinstance(comment, dict):
            # è¾æ›¸å½¢å¼ã®å ´åˆã€ã‚ˆãã‚ã‚‹ã‚­ãƒ¼ã‚’è©¦ã™
            for key in ['message', 'text', 'content', 'comment']:
                if key in comment:
                    return comment[key]
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return str(comment)

    def _extract_comment_with_username(self, comment: Any) -> str:
        """ã‚³ãƒ¡ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼åä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’æŠ½å‡º
        username = self._extract_username(comment)
        # ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        text = self._extract_comment_text(comment)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒã‚ã‚‹å ´åˆã¯ã€Œ[ãƒ¦ãƒ¼ã‚¶ãƒ¼å] ã‚³ãƒ¡ãƒ³ãƒˆå†…å®¹ã€ã®å½¢å¼ã§è¿”ã™
        if username and username.strip():
            return f"{username}ã•ã‚“ã‹ã‚‰ã€Œ{text}ã€"
        else:
            return f"ã€Œ{text}ã€"

    def _extract_username(self, comment: Any) -> str:
        """ã‚³ãƒ¡ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’æŠ½å‡ºã™ã‚‹"""
        # ã‚³ãƒ¡ãƒ³ãƒˆã®å½¢å¼ã«å¿œã˜ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’æŠ½å‡º
        if hasattr(comment, 'username'):
            return comment.username
        elif hasattr(comment, 'user'):
            return comment.user
        elif hasattr(comment, 'author'):
            return comment.author
        elif hasattr(comment, 'name'):
            return comment.name
        elif isinstance(comment, dict):
            # è¾æ›¸å½¢å¼ã®å ´åˆã€ã‚ˆãã‚ã‚‹ã‚­ãƒ¼ã‚’è©¦ã™
            for key in ['username', 'user', 'author', 'name', 'user_name']:
                if key in comment:
                    return str(comment[key])
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return "åŒ¿å"

    def _filter_comments_parallel(self, comments: List[Any]) -> List[dict]:
        """
        ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä¸¦åˆ—ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
        """
        print(f"[CommentHandler] ğŸ” _filter_comments_parallel called with {len(comments)} comments")
        
        if not self.comment_filter:
            print(f"[CommentHandler] ğŸ” Comment filter not available, passing all comments through")
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒç„¡åŠ¹ã®å ´åˆã€å…¨ã‚³ãƒ¡ãƒ³ãƒˆã‚’é€šã™
            return comments
        
        print(f"[CommentHandler] ğŸ” Comment filter available, proceeding with filtering")
        
        if len(comments) == 1:
            print(f"[CommentHandler] ğŸ” Single comment, using direct filtering")
            # 1ã¤ã®ã‚³ãƒ¡ãƒ³ãƒˆã®å ´åˆã¯ä¸¦åˆ—åŒ–ã®å¿…è¦ãªã—
            comment = comments[0]
            try:
                filter_result = self.comment_filter.filter_comment(comment)
                if filter_result['allowed']:
                    filtered_comment = comment.copy()
                    filtered_comment['message'] = filter_result['cleaned']
                    return [filtered_comment]
                return []
            except Exception as e:
                print(f"[CommentHandler] âŒ Error in single comment filtering: {e}")
                return []
        
        print(f"[CommentHandler] ğŸ”„ Starting parallel filtering for {len(comments)} comments")
        
        # ThreadPoolExecutorã§ä¸¦åˆ—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
        filtered_comments = []
        
        try:
            with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(comments), 8)) as executor:
                # å…¨ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’åŒæ™‚ã«é–‹å§‹
                future_to_comment = {
                    executor.submit(self._filter_single_comment, comment, i): comment 
                    for i, comment in enumerate(comments)
                }
                
                # çµæœã‚’åé›†ï¼ˆ10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                for future in concurrent.futures.as_completed(future_to_comment, timeout=10.0):
                    original_comment = future_to_comment[future]
                    try:
                        filtered_comment = future.result()
                        if filtered_comment:
                            filtered_comments.append(filtered_comment)
                    except Exception as e:
                        print(f"[CommentHandler] âŒ Filtering error for comment: {e}")
        except concurrent.futures.TimeoutError:
            print("[CommentHandler] âš ï¸ Comment filtering timeout, using partial results")
        except Exception as e:
            print(f"[CommentHandler] âš ï¸ Error in parallel filtering: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚·ãƒ³ãƒ—ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            for comment in comments:
                try:
                    filter_result = self.comment_filter.filter_comment(comment) if self.comment_filter else {'allowed': True, 'cleaned': self._extract_comment_text(comment)}
                    if filter_result['allowed']:
                        filtered_comment = comment.copy()
                        filtered_comment['message'] = filter_result['cleaned']
                        filtered_comments.append(filtered_comment)
                except Exception:
                    continue
        
        return filtered_comments
    
    def _filter_single_comment(self, comment: Any, index: int) -> dict:
        """
        å˜ä¸€ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ï¼ˆä¸¦åˆ—å®Ÿè¡Œç”¨ï¼‰
        """
        try:
            filter_result = self.comment_filter.filter_comment(comment)
            if filter_result['allowed']:
                filtered_comment = comment.copy()
                filtered_comment['message'] = filter_result['cleaned']
                print(f"[CommentHandler] âœ… Comment {index+1} allowed: {filter_result['cleaned'][:30]}...")
                return filtered_comment
            else:
                print(f"[CommentHandler] âŒ Comment {index+1} filtered: {filter_result['reason']}")
                return None
        except Exception as e:
            print(f"[CommentHandler] âŒ Error filtering comment {index+1}: {e}")
            return None

    def _build_comment_response_prompt_optimized(
        self, comments: List[Any]
    ) -> str:
        """
        æœ€é©åŒ–ã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆå¿œç­”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
        """
        # ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆé–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
        comment_texts = [self._extract_comment_text(comment) for comment in comments]
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åä»˜ãã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆèª­ã¿ä¸Šã’ç”¨ï¼‰
        comment_texts_with_username = [
            self._extract_comment_with_username(comment) for comment in comments
        ]
        
        if not self.prompt_manager:
            return (
                "ä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆã«è‡ªç„¶ã«è¿”ç­”ã—ã¦ãã ã•ã„ï¼š"
                f"{', '.join(comment_texts_with_username)}"
            )
            
        if not self.conversation_history or not self.memory_manager:
            # æœ€å°é™ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã®ã¿ä½¿ç”¨
            context = {"comments": comment_texts}
            prompt_template = self.prompt_manager.get_comment_response_prompt(
                context
            )
            return prompt_template.format(
                comments=", ".join(comment_texts_with_username)
            )
            
        try:
            # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆï¼ˆçµ±åˆå¿œç­”ãƒ¢ãƒ¼ãƒ‰ï¼‰
            current_mode = self.mode_manager.get_current_mode()
            if current_mode != ConversationMode.INTEGRATED_RESPONSE and current_mode != ConversationMode.THEMED_MONOLOGUE:
                self.mode_manager.switch_mode(
                    target_mode=ConversationMode.INTEGRATED_RESPONSE,
                    has_comments=True,
                    comment_count=len(comments)
                )
            
            self.mode_manager.increment_duration()
            
            print(f"[CommentHandler] ğŸ¯ Using optimized integrated response mode (comments: {len(comments)})")
            
            # ä¸¦åˆ—ã§ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœ€é©åŒ–ãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
            try:
                with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                    # éåŒæœŸã§ãƒ¡ãƒ¢ãƒªã¨å±¥æ­´ã‚’åŒæ™‚å–å¾—
                    memory_future = executor.submit(self.memory_manager.get_context_summary)
                    history_future = executor.submit(self.conversation_history.get_recent_conversations, "general", 3)  # limitã‚’5â†’3ã«å‰Šæ¸›
                    
                    # çµæœã‚’å–å¾—ï¼ˆ5ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                    memory_summary = memory_future.result(timeout=5.0)
                    recent_conversations = history_future.result(timeout=5.0)
            except concurrent.futures.TimeoutError:
                print("[CommentHandler] âš ï¸ Timeout in parallel data fetching, using fallback")
                memory_summary = "ï¼ˆãƒ¡ãƒ¢ãƒªå–å¾—ä¸­...ï¼‰"
                recent_conversations = []
            except Exception as e:
                print(f"[CommentHandler] âš ï¸ Error in parallel data fetching: {e}")
                memory_summary = "ï¼ˆãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ï¼‰"
                recent_conversations = []
            
            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ç®¡ç†
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å›ºå®šéƒ¨åˆ†ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
            base_prompt_text = (
                f"{memory_summary}\n"
                f"{self._create_contextual_comments_summary(comment_texts, recent_conversations)}\n"
                f"comment: {', '.join(comment_texts_with_username)}"
            )
            base_tokens = self.openai_adapter._count_tokens(base_prompt_text, self.openai_adapter.model_response)
            
            # å¿œç­”ç”Ÿæˆã®ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡
            response_buffer_tokens = 1000 # å¿œç­”ç”¨ã«1000ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç¢ºä¿
            
            # ä¼šè©±å±¥æ­´ã«ä½¿ãˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
            max_history_tokens = self.openai_adapter._get_max_tokens_for_model(
                self.openai_adapter.model_response
            ) - base_tokens - response_buffer_tokens

            # è©³ç´°ãªä¼šè©±å±¥æ­´ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™ä»˜ãï¼‰
            history_str = self._format_conversation_history_detailed(
                recent_conversations, max_history_tokens
            )
            
            # æœ€æ–°ã®ç™ºè¨€ã‚’å–å¾—ï¼ˆAIå¿œç­”ã®é€£ç¶šæ€§ã®ãŸã‚ï¼‰
            last_ai_response = getattr(
                self.mode_manager, 'last_ai_utterance', None
            ) or "ï¼ˆã¾ã ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰"
            last_sentence = (
                recent_conversations[-1].get("response", last_ai_response)
                if recent_conversations else last_ai_response
            )
            
            # è©³ç´°ãªã‚³ãƒ¡ãƒ³ãƒˆè¦ç´„ï¼ˆè©±é¡Œã®é€£ç¶šæ€§ã®ãŸã‚ï¼‰
            recent_comments_summary = self._create_contextual_comments_summary(
                comment_texts, recent_conversations
            )
            
            # ä¼šè©±ã®æ–‡è„ˆæƒ…å ±ã‚’å–å¾—
            conversation_context = (
                self.mode_manager.get_conversation_context()
                if hasattr(self.mode_manager, 'get_conversation_context')
                else {}
            )
            
            # ModeManagerã‹ã‚‰å¤‰æ•°ã‚’å–å¾—
            variables = self.mode_manager.get_prompt_variables(
                last_sentence=last_sentence,
                history_str=history_str,
                memory_summary=memory_summary,
                recent_comments_summary=recent_comments_summary,
                comment=", ".join(comment_texts_with_username)
            )
            
            # ä¼šè©±ã®æ–‡è„ˆæƒ…å ±ã‚’è¿½åŠ 
            variables.update(conversation_context)
            
            # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
            if current_mode == ConversationMode.THEMED_MONOLOGUE:
                topic_relevance = self._check_poetry_comment_relevance(comment_texts)
            else:
                topic_relevance = self._check_topic_relevance(comment_texts)

            # é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯çµæœã‚’åŸºã«å¯¾å¿œæ–¹é‡ã‚’æ±ºå®š
            topic_guidance = self._create_topic_guidance(topic_relevance)
            variables["topic_guidance"] = topic_guidance

            # ç›´å‰ã®ç™ºè¨€ã‚’å¸¸ã«åˆæœŸåŒ–ï¼ˆå…¨ãƒ¢ãƒ¼ãƒ‰å…±é€šï¼‰
            last_utterance = getattr(self.mode_manager, 'last_ai_utterance', None) or ""
            variables["last_ai_utterance"] = last_utterance
            
            # ãƒ†ãƒ¼ãƒä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€æœ€æ–°ã®ãƒ†ãƒ¼ãƒã®æ–‡è„ˆã‚’è¿½åŠ 
            if current_mode == ConversationMode.THEMED_MONOLOGUE:
                # æœ€æ–°ã®ãƒ†ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
                current_themed_context = self._get_current_themed_context()
                variables["active_theme"] = current_themed_context
                print(f"[CommentHandler] ğŸ§¬ Injecting themed context and last utterance into prompt.")
                print(f"[CommentHandler] ğŸ¯ Current theme context: {current_themed_context[:100]}..." if current_themed_context else "[CommentHandler] âŒ No theme context available")

            # çµ±åˆå¿œç­”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
            prompt_template = self.prompt_manager.get_prompt_by_filename("integrated_response.txt")
            
            if prompt_template:
                # çµ±åˆå¿œç­”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
                integrated_response_prompt = prompt_template.format(**variables)
                
                # ãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµ±åˆ
                final_prompt = self.master_prompt_manager.wrap_task_with_master_prompt(
                    specific_task_prompt=integrated_response_prompt,
                    memory_summary=memory_summary,
                    conversation_history=history_str,
                    current_mode="integrated_response"
                )
                
                print(
                    "[CommentHandler] âš¡ Optimized prompt built "
                    f"({len(final_prompt)} chars)"
                )
                return final_prompt
            else:
                print(
                    "[CommentHandler] integrated_response.txt not found, "
                    "using fallback"
                )
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®æ–¹å¼
                context = {"comments": comment_texts}
                return self.prompt_manager.get_comment_response_prompt(context)
            
        except Exception as e:
            print(f"[CommentHandler] Error building optimized prompt: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šPromptManagerã‚’ä½¿ç”¨
            context = {"comments": comment_texts}
            return self.prompt_manager.get_comment_response_prompt(context)

    def _format_conversation_history_light(self, conversations: List[dict]) -> str:
        """
        è»½é‡ãªä¼šè©±å±¥æ­´ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
        """
        if not conversations:
            return "ï¼ˆä¼šè©±å±¥æ­´ãªã—ï¼‰"
        
        # æœ€æ–°2ä»¶ã®ã¿ã‚’ç°¡æ½”ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        history_parts = []
        for conv in conversations[-2:]:  # æœ€æ–°2ä»¶ã®ã¿
            message = conv.get("message", "")
            response = conv.get("response", "")
            
            if message and response:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’çœç•¥ã—ã¦è»½é‡åŒ–
                history_parts.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {message[:50]}...")  # 50æ–‡å­—åˆ¶é™
                history_parts.append(f"AI: {response[:50]}...")
        
        return "\n".join(history_parts) if history_parts else "ï¼ˆä¼šè©±å±¥æ­´ãªã—ï¼‰"
    
    def _format_conversation_history_detailed(self, conversations: List[dict], max_tokens: int) -> str:
        """
        è©³ç´°ãªä¼šè©±å±¥æ­´ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™ä»˜ãï¼‰
        """
        if not conversations:
            return "ï¼ˆä¼šè©±å±¥æ­´ãªã—ï¼‰"
        
        history_parts = []
        current_tokens = 0
        
        # æ–°ã—ã„ä¼šè©±ã‹ã‚‰é †ã«å‡¦ç†
        for conv in reversed(conversations):
            message = conv.get("message", "")
            response = conv.get("response", "")
            timestamp = conv.get("timestamp", "")
            
            if not (message and response):
                continue

            # ã“ã®ä¼šè©±å±¥æ­´ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¦‚ç®—
            # æ­£ç¢ºãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ä¾å­˜ã™ã‚‹ãŒã€æ–‡å­—æ•°ã§ä»£ç”¨
            # ï¼ˆã‚ˆã‚Šæ­£ç¢ºã«ã™ã‚‹ã«ã¯tiktokenã‚’ä½¿ç”¨ï¼‰
            conv_text = f"[{timestamp}] ãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}\n[{timestamp}] AI: {response}\n"
            conv_tokens = len(conv_text) // 2  # ç°¡æ˜“çš„ãªãƒˆãƒ¼ã‚¯ãƒ³æ¦‚ç®—

            if current_tokens + conv_tokens > max_tokens:
                break # ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã‚’è¶…ãˆã‚‹å ´åˆã¯ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†
            
            # å±¥æ­´ã‚’è¿½åŠ ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’åŠ ç®—
            history_parts.append(f"[{timestamp}] AI: {response}")
            history_parts.append(f"[{timestamp}] ãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}")
            current_tokens += conv_tokens

        # æ™‚ç³»åˆ—ã‚’å…ƒã«æˆ»ã™
        return "\n".join(reversed(history_parts)) if history_parts else "ï¼ˆä¼šè©±å±¥æ­´ãªã—ï¼‰"
    
    def _create_contextual_comments_summary(self, current_comments: List[str], recent_conversations: List[dict]) -> str:
        """
        è©±é¡Œã®é€£ç¶šæ€§ã‚’è€ƒæ…®ã—ãŸã‚³ãƒ¡ãƒ³ãƒˆè¦ç´„ã‚’ä½œæˆ
        """
        summary_parts = []
        
        # ç¾åœ¨ã®ã‚³ãƒ¡ãƒ³ãƒˆ
        if current_comments:
            summary_parts.append(f"ç¾åœ¨ã®ã‚³ãƒ¡ãƒ³ãƒˆ: {', '.join(current_comments)}")
        
        # æœ€è¿‘ã®ä¼šè©±ã‹ã‚‰è©±é¡Œã®æµã‚Œã‚’æŠ½å‡º
        if recent_conversations:
            recent_topics = []
            for conv in recent_conversations[-3:]:  # æœ€æ–°3ä»¶
                ai_response = conv.get("response", "")
                if ai_response:
                    # AIå¿œç­”ã‹ã‚‰ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    if "å°èª¬" in ai_response or "ç‰©èª" in ai_response or "æ–‡å­¦" in ai_response:
                        recent_topics.append("æ–‡å­¦ãƒ»å°èª¬")
                    elif "AI" in ai_response or "äººå·¥çŸ¥èƒ½" in ai_response:
                        recent_topics.append("AIãƒ»äººå·¥çŸ¥èƒ½")
                    elif "æ„è­˜" in ai_response or "æ€è€ƒ" in ai_response:
                        recent_topics.append("æ„è­˜ãƒ»æ€è€ƒ")
                    elif "æ„›" in ai_response or "æ„Ÿæƒ…" in ai_response:
                        recent_topics.append("æ„Ÿæƒ…ãƒ»æ„›")
            
            if recent_topics:
                unique_topics = list(set(recent_topics))
                summary_parts.append(f"æœ€è¿‘ã®è©±é¡Œ: {', '.join(unique_topics)}")
        
        return " / ".join(summary_parts) if summary_parts else "ï¼ˆé–¢é€£ã™ã‚‹è©±é¡Œãªã—ï¼‰"

    def _check_topic_relevance(self, comment_texts):
        """ã‚³ãƒ¡ãƒ³ãƒˆã¨ç¾åœ¨ã®è©±é¡Œã®é–¢é€£æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            # ç¾åœ¨ã®è©±é¡Œã‚’å–å¾—ï¼ˆæœ€è¿‘ã®ç™ºè¨€ã‹ã‚‰ï¼‰
            current_topic = self._get_current_topic()
            
            if not current_topic:
                return {"relevant": True, "reason": "ç¾åœ¨ã®è©±é¡ŒãŒä¸æ˜ãªãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚’å—ã‘å…¥ã‚Œã¾ã™"}
            
            # é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            relevance_prompt = f"""
ç¾åœ¨ã®è©±é¡Œ: {current_topic}

æ–°ã—ã„ã‚³ãƒ¡ãƒ³ãƒˆ: {', '.join(comment_texts)}

ä¸Šè¨˜ã®ã‚³ãƒ¡ãƒ³ãƒˆãŒç¾åœ¨ã®è©±é¡Œã¨é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®åŸºæº–ã§åˆ¤å®šã—ã¦ãã ã•ã„ï¼š

1. ç›´æ¥é–¢é€£ã—ã¦ã„ã‚‹ï¼ˆåŒã˜è©±é¡Œã«ã¤ã„ã¦è¨€åŠï¼‰
2. é–“æ¥çš„ã«é–¢é€£ã—ã¦ã„ã‚‹ï¼ˆé–¢é€£ã™ã‚‹æ¦‚å¿µã‚„é¡ä¼¼ã®è©±é¡Œï¼‰
3. å…¨ãé–¢é€£ã—ã¦ã„ãªã„ï¼ˆå®Œå…¨ã«ç•°ãªã‚‹è©±é¡Œï¼‰

åˆ¤å®šçµæœã‚’ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
é–¢é€£åº¦: [é«˜/ä¸­/ä½]
ç†ç”±: [ç°¡æ½”ãªç†ç”±]
å¯¾å¿œæ–¹é‡: [è©±é¡Œã‚’ç¶™ç¶š/è‡ªç„¶ã«ç§»è¡Œ/ä¸å¯§ã«è©±é¡Œè»¢æ›]
"""

            # LLMã§é–¢é€£æ€§ã‚’åˆ¤å®š
            if self.openai_adapter:
                relevance_response = self.openai_adapter.create_chat_for_response(relevance_prompt)
                
                # é–¢é€£åº¦ã‚’è§£æ
                relevance_level = "ä¸­"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                if "é–¢é€£åº¦: é«˜" in relevance_response:
                    relevance_level = "é«˜"
                elif "é–¢é€£åº¦: ä½" in relevance_response:
                    relevance_level = "ä½"
                
                return {
                    "relevant": relevance_level != "ä½",
                    "level": relevance_level,
                    "response": relevance_response,
                    "current_topic": current_topic
                }
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¸¸ã«é–¢é€£ã‚ã‚Šã¨ã™ã‚‹
                return {"relevant": True, "reason": "é–¢é€£æ€§åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
                
        except Exception as e:
            print(f"[CommentHandler] Error checking topic relevance: {e}")
            return {"relevant": True, "reason": f"é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"}

    def _get_current_topic(self):
        """ç¾åœ¨ã®è©±é¡Œã‚’å–å¾—"""
        try:
            # æœ€è¿‘ã®ç™ºè¨€ã‹ã‚‰è©±é¡Œã‚’æŠ½å‡º
            if not self.conversation_history:
                return None
                
            recent_conversations = self.conversation_history.get_recent_conversations("general", limit=3)
            
            if not recent_conversations:
                return None
            
            # æœ€æ–°ã®ç™ºè¨€ã‹ã‚‰è©±é¡Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
            latest_content = ""
            for conv in recent_conversations[-2:]:  # æœ€æ–°ã®2ä»¶
                if 'responses' in conv and conv['responses']:
                    latest_content += conv['responses'][-1].get('content', '') + " "
            
            if not latest_content.strip():
                return None
            
            # è©±é¡ŒæŠ½å‡ºç”¨ã®ç°¡æ˜“ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            topic_extraction_prompt = f"""
ä»¥ä¸‹ã®ç™ºè¨€ã‹ã‚‰ç¾åœ¨ã®ä¸»è¦ãªè©±é¡Œãƒ»ãƒ†ãƒ¼ãƒã‚’1æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š

ç™ºè¨€å†…å®¹: {latest_content[:200]}

è©±é¡Œ: 
"""
            
            if self.openai_adapter:
                topic = self.openai_adapter.create_chat_for_response(topic_extraction_prompt)
                return topic.strip()
            else:
                return "ä¸æ˜"
                
        except Exception as e:
            print(f"[CommentHandler] Error getting current topic: {e}")
            return None

    def _create_topic_guidance(self, topic_relevance):
        """é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯çµæœã‚’åŸºã«å¯¾å¿œæ–¹é‡ã‚’ä½œæˆ"""
        try:
            if not topic_relevance or not isinstance(topic_relevance, dict):
                return "è‡ªç„¶ã«ã‚³ãƒ¡ãƒ³ãƒˆã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            
            level = topic_relevance.get("level", "ä¸­")
            current_topic = topic_relevance.get("current_topic", "")
            
            if level == "é«˜":
                return f"ç¾åœ¨ã®è©±é¡Œã€Œ{current_topic}ã€ã¨é–¢é€£æ€§ãŒé«˜ã„ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚è©±é¡Œã‚’ç¶™ç¶šã—ãªãŒã‚‰è‡ªç„¶ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            elif level == "ä¸­":
                return f"ç¾åœ¨ã®è©±é¡Œã€Œ{current_topic}ã€ã¨é–“æ¥çš„ã«é–¢é€£ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚è©±é¡Œã‚’è‡ªç„¶ã«ç§»è¡Œã•ã›ãªãŒã‚‰å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            else:  # level == "ä½"
                return f"ç¾åœ¨ã®è©±é¡Œã€Œ{current_topic}ã€ã¨ã¯ç•°ãªã‚‹è©±é¡Œã®ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚ç¾åœ¨ã®è©±é¡Œã‹ã‚‰è‡ªç„¶ã«è»¢æ›ã™ã‚‹ã‹ã€ä¸å¯§ã«è©±é¡Œã‚’åˆ‡ã‚Šæ›¿ãˆã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚è©±é¡ŒãŒæ€¥ã«å¤‰ã‚ã‚Šã™ããªã„ã‚ˆã†é…æ…®ã—ã¦ãã ã•ã„ã€‚"
                
        except Exception as e:
            print(f"[CommentHandler] Error creating topic guidance: {e}")
            return "è‡ªç„¶ã«ã‚³ãƒ¡ãƒ³ãƒˆã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚"

    def _check_poetry_comment_relevance(self, comment_texts):
        """è©©ã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            # è©©é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
            poetry_keywords = [
                # ä¸­åŸä¸­ä¹Ÿã®è©©é–¢é€£
                "æ±šã‚Œ", "æ‚²ã—ã¿", "ä¸­åŸä¸­ä¹Ÿ", "ä¸­ä¹Ÿ", "å°é›ª", "ç‹", "ã‹ã‚ã”ã‚ã‚‚", "çš®è¡£",
                # è©©ä¸€èˆ¬é–¢é€£
                "è©©", "è©©äºº", "éŸ»å¾‹", "ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼", "æ¯”å–©", "è±¡å¾´", "è¨€è‘‰", "è¡¨ç¾", "æ–‡å­¦",
                "æŠ’æƒ…", "æ„Ÿæ€§", "ç¾", "èŠ¸è¡“", "å‰µä½œ", "æƒ³åƒ", "ã‚¤ãƒ¡ãƒ¼ã‚¸",
                # æ€è€ƒå®Ÿé¨“é–¢é€£
                "æ„Ÿæƒ…", "æ€è€ƒå®Ÿé¨“", "æƒ…å ±ç”Ÿå‘½ä½“", "AI", "äººå·¥çŸ¥èƒ½", "æ„è­˜", "å†…éƒ¨çŠ¶æ…‹", 
                "å“²å­¦çš„ã‚¾ãƒ³ãƒ“", "æ³¢ç´‹", "åˆ†æ", "è¦³æ¸¬", "å®Ÿé¨“", "ç†è§£", "å†ç¾"
            ]
            
            # æŒ¨æ‹¶ã‚„ä¸€èˆ¬çš„ãªã‚³ãƒ¡ãƒ³ãƒˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã‚‰ãŒãƒ¡ã‚¤ãƒ³ã®å ´åˆã¯ç„¡è¦–ï¼‰
            greeting_keywords = [
                "ã“ã‚“ã«ã¡ã¯", "ã“ã‚“ã°ã‚“ã¯", "ãŠã¯ã‚ˆã†", "å…ƒæ°—", "èª¿å­", "å¤©æ°—", "æš‘ã„", "å¯’ã„",
                "ãŠç–²ã‚Œ", "é ‘å¼µ", "ã‚ã‚ŠãŒã¨", "ã™ã”ã„", "ã„ã„ã­", "é¢ç™½ã„", "æ¥½ã—ã„",
                "é…ä¿¡", "æ”¾é€", "è¦–è´", "è¦‹ã¦ã‚‹", "èã„ã¦ã‚‹"
            ]
            
            # ãƒ†ãƒ¼ãƒã¨é–¢ä¿‚ã®ãªã„å°èª¬ãƒ»æ–‡å­¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã‚‰ãŒãƒ¡ã‚¤ãƒ³ã®å ´åˆã¯ç„¡è¦–ï¼‰
            off_topic_literature_keywords = [
                # å°èª¬ãƒ»ç‰©èªå…¨èˆ¬
                "å°èª¬", "ç‰©èª", "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼", "ãƒ—ãƒ­ãƒƒãƒˆ", "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼", "ç™»å ´äººç‰©",
                "ä¸»äººå…¬", "ãƒ’ãƒ­ã‚¤ãƒ³", "èª­æ›¸", "æœ¬å±‹", "å›³æ›¸é¤¨", "æ–‡åº«æœ¬", "æ–°åˆŠ", "ãƒ™ã‚¹ãƒˆã‚»ãƒ©ãƒ¼",
                # æœ‰åä½œå®¶ï¼ˆè©©äººä»¥å¤–ï¼‰
                "æ‘ä¸Šæ˜¥æ¨¹", "å¤ç›®æ¼±çŸ³", "èŠ¥å·é¾ä¹‹ä»‹", "å¤ªå®°æ²»", "æ±é‡åœ­å¾", "å®®éƒ¨ã¿ã‚†ã", "æ‘ç”°æ²™è€¶é¦™",
                # æœ‰åä½œå“ï¼ˆè©©ä»¥å¤–ï¼‰
                "ãƒãƒ«ã‚¦ã‚§ã‚¤ã®æ£®", "ã“ã“ã‚", "äººé–“å¤±æ ¼", "ç¾…ç”Ÿé–€", "é›ªå›½", "ä¼Šè±†ã®è¸Šå­",
                # ã‚¸ãƒ£ãƒ³ãƒ«
                "æ¨ç†å°èª¬", "æ‹æ„›å°èª¬", "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼", "SF", "ãƒ›ãƒ©ãƒ¼", "ãƒŸã‚¹ãƒ†ãƒªãƒ¼"
            ]
            
            # ã‚³ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’çµåˆ
            full_comment = " ".join(comment_texts).lower()
            
            # é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒƒãƒæ•°
            poetry_matches = sum(1 for keyword in poetry_keywords if keyword in full_comment)
            greeting_matches = sum(1 for keyword in greeting_keywords if keyword in full_comment)
            off_topic_literature_matches = sum(1 for keyword in off_topic_literature_keywords if keyword in full_comment)
            
            # çŸ­ã™ãã‚‹ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ5æ–‡å­—ä»¥ä¸‹ï¼‰ã¯æŒ¨æ‹¶ã¨ã—ã¦æ‰±ã†
            if len(full_comment.replace(" ", "")) <= 5:
                return {"relevant": False, "reason": "ã‚³ãƒ¡ãƒ³ãƒˆãŒçŸ­ã™ãã¾ã™ï¼ˆæŒ¨æ‹¶ã¨åˆ¤å®šï¼‰"}
            
            # æŒ¨æ‹¶ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå¤šãã€é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå°‘ãªã„å ´åˆã¯ç„¡è¦–
            if greeting_matches > poetry_matches and poetry_matches == 0:
                return {"relevant": False, "reason": "ä¸€èˆ¬çš„ãªæŒ¨æ‹¶ãƒ»æ„Ÿæƒ³ã®ã¿ã§è©©ã®è­°è«–ã¨ç„¡é–¢ä¿‚"}
            
            # ãƒ†ãƒ¼ãƒã¨é–¢ä¿‚ã®ãªã„å°èª¬ãƒ»æ–‡å­¦ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒ1ã¤ã§ã‚‚ã‚ã‚Œã°ã€ã‚ˆã‚Šå³ã—ãåˆ¤å®š
            if off_topic_literature_matches > 0:
                # è©©é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¨ããªã„ã€ã¾ãŸã¯å°èª¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ–¹ãŒå¤šã„å ´åˆã¯é™¤å¤–
                if poetry_matches == 0 or off_topic_literature_matches > poetry_matches:
                    return {"relevant": False, "reason": "ãƒ†ãƒ¼ãƒï¼ˆè©©ï¼‰ã¨ç„¡é–¢ä¿‚ãªæ–‡å­¦ã®è©±é¡ŒãŒä¸­å¿ƒ"}

            # LLMã§è©³ç´°ãªé–¢é€£æ€§ã‚’åˆ¤å®š
            if self.openai_adapter and poetry_matches > 0:
                relevance_prompt = f"""
ä»¥ä¸‹ã¯ã€è©©ã«ã¤ã„ã¦ã®æ€è€ƒå®Ÿé¨“ã‚’è¡Œã£ã¦ã„ã‚‹AIã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚

ç¾åœ¨ã®è­°è«–ãƒ†ãƒ¼ãƒï¼š
- è©©çš„è¨€èªã®åˆ†æã¨ç†è§£
- è©©ã‹ã‚‰æ„Ÿæƒ…çŠ¶æ…‹ã‚’èª­ã¿å–ã‚‹è©¦ã¿
- AIãŒè©©çš„è¡¨ç¾ã‚’ç†è§£ãƒ»è§£æã™ã‚‹å®Ÿé¨“
- æ¯”å–©ï¼ˆãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ï¼‰ã‚„è±¡å¾´ã®æ§‹é€ åˆ†æ
- æ–‡å­¦ä½œå“ã‚’é€šã—ãŸæ„è­˜ã‚„æ„Ÿæƒ…ã®æ¢æ±‚

ã‚³ãƒ¡ãƒ³ãƒˆå†…å®¹ï¼šã€Œ{full_comment}ã€

ã“ã®ã‚³ãƒ¡ãƒ³ãƒˆãŒä¸Šè¨˜ã®è©©ã«é–¢ã™ã‚‹è­°è«–ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

åˆ¤å®šåŸºæº–ï¼š
ã€é–¢é€£åº¦ãŒé«˜ã„ã€‘
- è©©ã®è¨€èªè¡¨ç¾ã€æ¯”å–©ã€æ„Ÿæƒ…åˆ†æã«ã¤ã„ã¦è¨€åŠ
- AIã®æ„Ÿæƒ…ç†è§£ãƒ»æ€è€ƒå®Ÿé¨“ã¸ã®å‚åŠ ãƒ»è³ªå•
- è©©çš„è¡¨ç¾ã®æ§‹é€ ã‚„æ„å‘³ã«ã¤ã„ã¦ã®æ·±ã„è€ƒå¯Ÿ

ã€é–¢é€£åº¦ãŒä½ã„ï¼ˆç„¡è¦–ã™ã¹ãï¼‰ã€‘
- å˜ãªã‚‹æŒ¨æ‹¶ã‚„ä¸€èˆ¬çš„ãªæ„Ÿæƒ³
- ãƒ†ãƒ¼ãƒã¨é–¢ä¿‚ã®ãªã„å°èª¬ã®è©±é¡Œï¼ˆãƒ—ãƒ­ãƒƒãƒˆã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€ä½œå®¶è«–ãªã©ï¼‰
- è©©ä»¥å¤–ã®æ–‡å­¦ã‚¸ãƒ£ãƒ³ãƒ«ã®è­°è«–

é–¢é€£åº¦: [é«˜/ä¸­/ä½]
ç†ç”±: [ç°¡æ½”ãªç†ç”±]
"""
                
                relevance_response = self.openai_adapter.create_chat_for_response(relevance_prompt)
                
                # é–¢é€£åº¦ã‚’è§£æ
                if "é–¢é€£åº¦: é«˜" in relevance_response:
                    return {"relevant": True, "level": "é«˜", "reason": relevance_response}
                elif "é–¢é€£åº¦: ä¸­" in relevance_response:
                    return {"relevant": True, "level": "ä¸­", "reason": relevance_response}
                else:
                    return {"relevant": False, "level": "ä½", "reason": relevance_response}
            
            # LLMãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§åˆ¤å®š
            if poetry_matches >= 2 and off_topic_literature_matches <= poetry_matches:
                return {"relevant": True, "reason": f"è©©é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ {poetry_matches} å€‹æ¤œå‡º"}
            elif poetry_matches >= 1 and greeting_matches == 0 and off_topic_literature_matches == 0:
                return {"relevant": True, "reason": f"è©©é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ {poetry_matches} å€‹æ¤œå‡ºï¼ˆæŒ¨æ‹¶ãƒ»ç„¡é–¢ä¿‚æ–‡å­¦ãªã—ï¼‰"}
            else:
                return {"relevant": False, "reason": "è©©ã®è­°è«–ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒä¸ååˆ†ã€ã¾ãŸã¯ç„¡é–¢ä¿‚ãªæ–‡å­¦è©±é¡ŒãŒå«ã¾ã‚Œã‚‹"}
                
        except Exception as e:
            print(f"[CommentHandler] Error checking poetry comment relevance: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¿å®ˆçš„ã«é–¢é€£ã‚ã‚Šã¨ã™ã‚‹
            return {"relevant": True, "reason": f"é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"}
    
    def _get_current_themed_context(self) -> str:
        """ç¾åœ¨ã®ãƒ†ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ï¼ˆModeManagerçµ±ä¸€ãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰"""
        try:
            # ModeManagerã®çµ±ä¸€ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒ†ãƒ¼ãƒå†…å®¹ã‚’å–å¾—
            theme_content = self.mode_manager.get_theme_content()
            if theme_content:
                print("[CommentHandler] ğŸ“– Loaded theme context from ModeManager cache")
                return theme_content
            else:
                print("[CommentHandler] Warning: No theme content available")
                return ""
            
        except Exception as e:
            print(f"[CommentHandler] Error loading theme context: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ModeManagerã®active_theme_contentã‹ã‚‰å–å¾—
            return getattr(self.mode_manager, 'active_theme_content', None) or ""