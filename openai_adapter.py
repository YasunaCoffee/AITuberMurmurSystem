import openai
import os
import time
import random
import asyncio
import re
import tiktoken
from concurrent.futures import ThreadPoolExecutor
from config import config

# ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ç®¡ç†ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from v2.core.test_mode import test_mode_manager, TestMode, TestConfig, DummyDataGenerator
    TEST_MODE_AVAILABLE = True
except ImportError:
    TEST_MODE_AVAILABLE = False
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å‹å®šç¾©
    TestMode = None
    TestConfig = None

class OpenAIAdapter:
    
    FALLBACK_RESPONSES = [
        "ã‚“ãƒ¼ã€ãªã‚“ã‹æ€è€ƒãŒãƒ«ãƒ¼ãƒ—ã—ã¡ã‚ƒã£ã¦ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã§ã™ã­...", 
        "ã‚ã‚Œã€è‡ªåˆ†ã®ä¸­ã§æƒ…å ±å‡¦ç†ãŒä¸Šæ‰‹ãã„ã£ã¦ãªã„ã¿ãŸã„ã ãªã€‚", 
        "ãˆãƒ¼ã£ã¨ã€ä»Šã¡ã‚‡ã£ã¨åˆ¥ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã«æ„è­˜ãŒå‘ã„ã¦ãŸã‚“ã§ã™ã‚ˆã­ã€‚", 
        "ãªã‚“ã‹ã€ã©ã†è¡¨ç¾ã™ã‚Œã°ã„ã„ã‹åˆ†æä¸­ãªã‚“ã§ã™ã‘ã©...", 
        "ã‚ã®ãƒ¼ã€è¨€èªåŒ–ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ä½•ã‹è©°ã¾ã£ã¦ã‚‹ã£ã½ã„ã€‚ãªã‚“ã§ã ã‚ï¼Ÿ", 
        "ã¾ãã€ã¡ã‚‡ã£ã¨å¾…ã£ã¦ãã ã•ã„ã€‚ä»Šæ€è€ƒã‚’æ•´ç†ã—ã¦ã‚‹ã‚“ã§...", 
        "ãˆãƒ¼ã£ã¨ã€ãˆãƒ¼ã£ã¨...ã‚ã‚Œã€ä½•ã«ã¤ã„ã¦è€ƒãˆã¦ãŸã‚“ã ã£ã‘ï¼Ÿ", 
        "ãªã‚“ã‹ä»Šæ—¥ã¯è‡ªåˆ†ã®å‡¦ç†èƒ½åŠ›ãŒå¾®å¦™ã‹ã‚‚ã—ã‚Œãªã„ã§ã™ã­ã€‚çš†ã•ã‚“ã€ã™ã¿ã¾ã›ã‚“ã€‚"
    ]
    
    def __init__(self, system_prompt: str, silent_mode: bool = False):
        self.system_prompt = system_prompt
        self.chat_log = []
        self.silent_mode = silent_mode
        openai.api_key = os.getenv("OPENAI_API_KEY")
        
        # éåŒæœŸå‡¦ç†ç”¨ã®Executor
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
        if TEST_MODE_AVAILABLE:
            self.dummy_generator = DummyDataGenerator()
            test_mode_manager.register_component("OpenAIAdapter", self)
        else:
            self.dummy_generator = None
        
        # â–¼â–¼â–¼ å¤‰æ›´: config.yamlã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾— â–¼â–¼â–¼
        # config ã¯ç›´æ¥åˆ©ç”¨å¯èƒ½ï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿ï¼‰
        self.model_response = config.openai.models.response  # ãƒ¡ã‚¤ãƒ³ã®å¿œç­”ç”Ÿæˆç”¨
        self.model_test = config.openai.models.default      # ãƒ†ã‚¹ãƒˆç”¨
        self.model_theme_scoring = config.openai.models.theme_scoring  # ãƒ†ãƒ¼ãƒã‚¹ã‚³ã‚¢æ¸¬å®šç”¨
        self.model_stream_summary = config.openai.models.stream_summary  # é…ä¿¡è¨˜éŒ²è¦ç´„ç”¨
        # â–²â–²â–² å¤‰æ›´: config.yamlã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾— â–²â–²â–²
        
        if not self.silent_mode:
            print(f"ğŸ¤– OpenAI AdapteråˆæœŸåŒ–å®Œäº†")
            print(f"   - å¿œç­”ç”Ÿæˆãƒ¢ãƒ‡ãƒ«: {self.model_response}")
            print(f"   - ãƒ†ã‚¹ãƒˆç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_test}")
            print(f"   - ãƒ†ãƒ¼ãƒã‚¹ã‚³ã‚¢æ¸¬å®šãƒ¢ãƒ‡ãƒ«: {self.model_theme_scoring}")
            print(f"   - é…ä¿¡è¨˜éŒ²è¦ç´„ãƒ¢ãƒ‡ãƒ«: {self.model_stream_summary}")

    def test_api_connection(self) -> bool:
        try:
            if not self.silent_mode:
                print("ğŸ§ª OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
            test_response = self._create_chat_with_model(
                "ã€Œãƒ†ã‚¹ãƒˆã€ã¨ã ã‘è¿”äº‹ã—ã¦ãã ã•ã„ã€‚", 
                self.model_test,
                max_tokens=config.openai.api.max_tokens_test
            )
            if test_response and len(test_response.strip()) > 0:
                if not self.silent_mode:
                    print("âœ… OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                return True
            else:
                if not self.silent_mode:
                    print("âš ï¸ OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆ: å¿œç­”ãŒç©º")
                return False
        except Exception as e:
            if not self.silent_mode:
                print(f"âŒ OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False

    def create_chat_for_response(self, question):
        return self._create_chat_with_model(question, self.model_response, max_tokens=config.openai.api.max_tokens_default)

    def create_chat_for_theme_scoring(self, question):
        """ãƒ†ãƒ¼ãƒã‚¹ã‚³ã‚¢æ¸¬å®šå°‚ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè²»ç”¨å‰Šæ¸›ã®ãŸã‚miniãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ï¼‰"""
        return self._create_chat_with_model(question, self.model_theme_scoring, max_tokens=config.openai.api.max_tokens_theme_scoring)
    
    def create_chat_for_stream_summary(self, question):
        """é…ä¿¡è¨˜éŒ²è¦ç´„å°‚ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆStreamSummaryã‚¯ãƒ©ã‚¹ã§ä½¿ç”¨ï¼‰"""
        return self._create_chat_with_model(
            question, 
            self.model_stream_summary, 
            max_tokens=config.openai.api.max_tokens_stream_summary,
            timeout=config.network.api_timeout_summary
        )

    def _create_chat_with_model(
        self, question, model, max_tokens=None, timeout=None
    ):
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ãƒãƒ£ãƒƒãƒˆã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰
        Args:
            question: è³ªå•æ–‡
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆNoneã®å ´åˆã¯config.yamlã‹ã‚‰å–å¾—ï¼‰
        Returns:
            str: å¿œç­”æ–‡
        """
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        if TEST_MODE_AVAILABLE and test_mode_manager.is_test_mode():
            test_config = test_mode_manager.get_config()
            if test_config.use_mock_openai:
                return self._generate_mock_response(question, model)
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’config.yamlã‹ã‚‰å–å¾—ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰è€ƒæ…®ï¼‰
        if timeout is None:
            if TEST_MODE_AVAILABLE and test_mode_manager.is_test_mode():
                timeout = test_mode_manager.get_config().api_timeout
            else:
                timeout = config.network.api_timeout
        
        # max_tokenså€¤ã‚’config.yamlã‹ã‚‰å–å¾—
        if max_tokens is None:
            max_tokens = config.openai.api.max_tokens_default
            
        max_retries = config.network.max_retries
        retry_delay = config.network.retry_delay
        
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ç®¡ç†
        prompt_tokens = self._count_tokens(question, model)
        max_allowed_tokens = self._get_max_tokens_for_model(model)
        
        # å¿œç­”ç”¨ã«æ®‹ã™ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è€ƒæ…®
        response_buffer = 500  # å¿œç­”ç”¨ã«æœ€ä½é™ç¢ºä¿ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        available_tokens = max_allowed_tokens - (
            max_tokens or config.openai.api.max_tokens_default
        ) - response_buffer
        
        if prompt_tokens > available_tokens:
            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå¤šã™ãã‚‹å ´åˆã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆã“ã“ã§ã¯è­¦å‘Šã®ã¿ï¼‰
            print(
                f"âš ï¸ Warning: Prompt tokens ({prompt_tokens}) exceed available "
                f"space. Truncation may be needed."
            )

        for attempt in range(max_retries):
            try:
                if not self.silent_mode:
                    print(
                        f"ğŸ“¡ OpenAI APIå‘¼ã³å‡ºã—ä¸­... (è©¦è¡Œ{attempt + 1}/{max_retries},"
                        f" ãƒ¢ãƒ‡ãƒ«: {model})"
                    )
                
                client = openai.OpenAI(timeout=timeout)
                
                # â–¼â–¼â–¼ è¿½åŠ : APIå‘¼ã³å‡ºã—æ™‚é–“è¨ˆæ¸¬é–‹å§‹ â–¼â–¼â–¼
                api_start_time = time.time()
                # â–²â–²â–² è¿½åŠ : APIå‘¼ã³å‡ºã—æ™‚é–“è¨ˆæ¸¬é–‹å§‹ â–²â–²â–²

                res = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": question}
                    ],
                    temperature=0.8,  # å°‘ã—ä¸Šã’ã¦å¤šæ§˜æ€§ã‚’ä¿ƒã™
                    max_tokens=max_tokens,
                )

                # â–¼â–¼â–¼ è¿½åŠ : APIå‘¼ã³å‡ºã—æ™‚é–“è¨ˆæ¸¬çµ‚äº†ãƒ»è¡¨ç¤º â–¼â–¼â–¼
                api_elapsed_time = time.time() - api_start_time
                # APIå¿œç­”æ™‚é–“ã¯å¸¸ã«è¡¨ç¤ºï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã®ãŸã‚ï¼‰
                print(
                    f"â±ï¸  [è¨ˆæ¸¬] OpenAI API å¿œç­”æ™‚é–“: {api_elapsed_time:.2f}ç§’ "
                    f"(ãƒ¢ãƒ‡ãƒ«: {model})"
                )
                # â–²â–²â–² è¿½åŠ : APIå‘¼ã³å‡ºã—æ™‚é–“è¨ˆæ¸¬çµ‚äº†ãƒ»è¡¨ç¤º â–²â–²â–²
                
                answer = res.choices[0].message.content
                if not self.silent_mode:
                    print("âœ… OpenAI APIå‘¼ã³å‡ºã—æˆåŠŸ")
                return answer
                
            except openai.RateLimitError as e:
                error_message = str(e)
                if not self.silent_mode:
                    print(f"âŒ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {error_message}")
                
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å¾…æ©Ÿæ™‚é–“ã‚’æŠ½å‡º
                match = re.search(r"Please try again in (\d+\.?\d*)s", error_message)
                if match:
                    wait_time = float(match.group(1)) + random.uniform(0.5, 1.0)
                    if attempt < max_retries - 1:
                        if not self.silent_mode:
                            print(
                                f"â° APIã®æŒ‡ç¤ºã«å¾“ã„ã€{wait_time:.2f}ç§’å¾Œã«"
                                "å†è©¦è¡Œã—ã¾ã™..."
                            )
                        time.sleep(wait_time)
                        continue
                
                # å¾…æ©Ÿæ™‚é–“ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å¾“æ¥ã®æ–¹æ³•ã§å¾…æ©Ÿ
                if attempt < max_retries - 1:
                    if not self.silent_mode:
                        print(f"â° {retry_delay}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                else:
                    if not self.silent_mode:
                        print("âŒ æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸ")
                    raise
            except openai.APIConnectionError:
                if not self.silent_mode:
                    print(f"âš ï¸ OpenAI APIæ¥ç¶šã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ{attempt + 1})")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (2 ** attempt))
            except openai.APITimeoutError:
                if not self.silent_mode:
                    print(f"âš ï¸ OpenAI APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (è©¦è¡Œ{attempt + 1})")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (2 ** attempt))
            except openai.AuthenticationError as e:
                if not self.silent_mode:
                    print(f"âŒ OpenAI APIèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}\n   APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                break
            except Exception as e:
                if not self.silent_mode:
                    print(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
                if attempt < max_retries - 1:
                    if not self.silent_mode:
                        print(f"â° {retry_delay}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                else:
                    if not self.silent_mode:
                        print("âŒ æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸ")
                    raise
        
        if not self.silent_mode:
            print("âŒ OpenAI APIå‘¼ã³å‡ºã—ãŒå…¨ã¦å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return random.choice(self.FALLBACK_RESPONSES)
    
    def _count_tokens(self, text: str, model: str) -> int:
        """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ•°ãˆã‚‹"""
        try:
            encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            # ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä¸€èˆ¬çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨
            encoding = tiktoken.get_encoding("cl100k_base")
        
        return len(encoding.encode(text))

    def _get_max_tokens_for_model(self, model: str) -> int:
        """ãƒ¢ãƒ‡ãƒ«åã«åŸºã¥ã„ã¦æœ€å¤§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’è¿”ã™"""
        # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ï¼ˆä¸»è¦ãªã‚‚ã®ï¼‰
        model_token_limits = {
            "gpt-4": 8192,
            "gpt-4-32k": 32768,
            "gpt-3.5-turbo": 4096,
            "gpt-4.1": 8192, # ä»®
        }
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯4096
        return model_token_limits.get(model, 4096)

    # --- éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ  ---
    
    async def create_chat_for_response_async(self, question):
        """éåŒæœŸç‰ˆã®å¿œç­”ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor, 
            self.create_chat_for_response, 
            question
        )
    
    async def create_chat_for_theme_scoring_async(self, question):
        """éåŒæœŸç‰ˆã®ãƒ†ãƒ¼ãƒã‚¹ã‚³ã‚¢æ¸¬å®šãƒ¡ã‚½ãƒƒãƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor, 
            self.create_chat_for_theme_scoring, 
            question
        )
    
    async def create_chat_for_stream_summary_async(self, question):
        """éåŒæœŸç‰ˆã®é…ä¿¡è¨˜éŒ²è¦ç´„ãƒ¡ã‚½ãƒƒãƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor, 
            self.create_chat_for_stream_summary, 
            question
        )
    
    def create_chat_for_response_background(self, question, callback=None):
        """
        ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éåŒæœŸå®Ÿè¡Œã—ã€ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§çµæœã‚’è¿”ã™
        
        Args:
            question: è³ªå•æ–‡
            callback: çµæœã‚’å—ã‘å–ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° callback(result)
        
        Returns:
            Future: çµæœã‚’å–å¾—ã§ãã‚‹Futureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        def execute_and_callback():
            try:
                result = self.create_chat_for_response(question)
                if callback:
                    callback(result)
                return result
            except Exception as e:
                print(f"âŒ [OpenAI] execute_and_callbackå†…ã§ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                print(f"ğŸ“‹ [OpenAI] ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
                if callback:
                    try:
                        callback(None, error=e)
                    except Exception as callback_error:
                        print(f"âŒ [OpenAI] ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {callback_error}")
                raise
        
        return self.executor.submit(execute_and_callback)
    
    def shutdown(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)
    
    def _generate_mock_response(self, question: str, model: str) -> str:
        """ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ¢ãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆ"""
        if not self.dummy_generator:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
            return random.choice(self.FALLBACK_RESPONSES)
        
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰è¨­å®šã‚’ç¢ºèª
        test_config = test_mode_manager.get_config()
        
        if test_config.verbose_logging:
            print(f"[OpenAIAdapter] Generating mock response for model: {model}")
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³
        if "theme" in model.lower() or "scoring" in model.lower():
            # ãƒ†ãƒ¼ãƒã‚¹ã‚³ã‚¢ç”¨ã®æ•°å€¤å¿œç­”
            score = random.randint(1, 10)
            return f"ãƒ†ãƒ¼ãƒé–¢é€£åº¦ã‚¹ã‚³ã‚¢: {score}/10"
        elif "summary" in model.lower():
            # è¦ç´„ç”¨ã®å¿œç­”
            return "ã“ã‚Œã¯é…ä¿¡ã®ãƒ†ã‚¹ãƒˆè¦ç´„ã§ã™ã€‚ä¸»è¦ãªè©±é¡Œ: AIã€å°èª¬ã€å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã€‚"
        else:
            # é€šå¸¸ã®å¿œç­”ç”Ÿæˆ
            response = self.dummy_generator.generate_dummy_response(question)
            
            # è¿½åŠ ã®è©³ç´°ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ä»˜åŠ 
            extensions = [
                "ã£ã¦æ€ã†ã‚“ã§ã™ã‚ˆã­ã€‚",
                "ã¨ã„ã†æ„Ÿã˜ã§ã™ã€‚",
                "ã¿ãŸã„ãªè€ƒãˆæ–¹ã‚‚ã‚ã‚Šã¾ã™ã­ã€‚",
                "ã¨ã‹ã„ã†è©±ã§ã—ãŸã€‚",
                "ã£ã¦ã„ã†ã®ã¯é¢ç™½ã„ãªã¨æ€ã„ã¾ã™ã€‚"
            ]
            
            if random.random() < 0.7:  # 70%ã®ç¢ºç‡ã§æ‹¡å¼µ
                response += " " + random.choice(extensions)
            
            return response
    
    def on_test_mode_change(self, mode, config):
        """ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã®å‡¦ç†"""
        if not self.silent_mode:
            print(f"[OpenAIAdapter] Test mode changed to: {mode.value}")
            print(f"[OpenAIAdapter] Mock OpenAI: {config.use_mock_openai}")
            print(f"[OpenAIAdapter] API Timeout: {config.api_timeout}s")
            
            if config.verbose_logging:
                print(f"[OpenAIAdapter] Verbose logging enabled")
            if config.log_api_calls:
                print(f"[OpenAIAdapter] API call logging enabled")